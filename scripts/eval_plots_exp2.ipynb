{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "from matplotlib.ticker import ScalarFormatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "palette = sns.color_palette()\n",
    "color_matching = {\n",
    "    \"ELEET\": palette[0],  # blue\n",
    "    \"Text-To-Table\": palette[2],  # green\n",
    "    \"LLaMA-2 7B (ic)\": palette[1],  # orange\n",
    "    \"LLaMA-2 7B (ft)\": palette[3],  # red\n",
    "    \"gpt-3.5-turbo-0125\": palette[4],  #purple\n",
    "    \"gpt-4-0613\": palette[6]\n",
    "}\n",
    "methods = [\"ELEET\", \"Text-To-Table\", \"LLaMA-2 7B (ic)\", \"LLaMA-2 7B (ft)\"]\n",
    "\n",
    "hue_methods = [\"LLaMA-2 7B (ic)\", \"LLaMA-2 7B (ft)\", \"ELEET\", \"Text-To-Table\"]\n",
    "color_palette = [color_matching[m] for m in hue_methods]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from eleet.evaluate import RunDescription\n",
    "\n",
    "# METRICS_FILE = \"../predictions/test/metrics_eleet-t2t-gpt-gpt4-llama-bert-tabert-gpt-ft-rotowire-all-test-limit-4294967296.csv\"\n",
    "METRICS_FILE = \"../predictions/test/metrics_eleet-t2t-llama-gpt-3.5-turbo-0125-gpt-4-0613-llama-ft-gpt-ft-rotowire-all-test-limit-4294967296.csv\"\n",
    "PERF_METRIC = \"mean_f1\"\n",
    "\n",
    "query_dict = {'G_name(π_name,Assists,Blocks,Points,To…(Player))': 'Aggregation',\n",
    "              'player_info ⨝ player_to_reports ⨝ Player': 'Join',\n",
    "              'player_stats ∪ Player': 'Union',\n",
    "              'π_name,Assists,Blocks,Points,To…(Player)': 'Scan',\n",
    "              'π_name,Assists,Blocks,Points,To…(σ_Points=28[0.096](Player))': 'Selection'}\n",
    "\n",
    "metrics = pd.read_csv(METRICS_FILE)\n",
    "metrics[\"method\"] = metrics[\"method\"].apply(lambda x: \"gpt-3.5-turbo (ft)\" if x.startswith(\"ft:\") else x)\n",
    "metrics.replace({\"ELEET\": \"ELEET\", \"LLaMA\": \"LLaMA-2 7B (ic)\", 4096: 3398, 16384: 3398, \"LLaMA-FT\": \"LLaMA-2 7B (ft)\", \"gpt-3.5-turbo-0125\": \"gpt-3.5-turbo-0125 (ic)\",\n",
    "                 \"gpt-4-0613\": \"gpt-4-0613 (ic)\", **query_dict}, inplace=True)\n",
    "\n",
    "# adjustments\n",
    "metrics = metrics[metrics[\"split_size\"] < 4000]  # dataset is smaller than 4000\n",
    "metrics = metrics.loc[~((metrics[\"method\"] == \"LLaMA-2 7B (ic)\") & (metrics[\"split_size\"] > 4))]  # context size too small\n",
    "metrics.loc[metrics[\"method\"] == \"gpt-4-0613 (ic)\", \"split_size\"] = 4\n",
    "\n",
    "\n",
    "\n",
    "slm = [\"ELEET\", \"Text-To-Table\"]\n",
    "in_context = [\"LLaMA-2 7B (ic)\", \"gpt-3.5-turbo-0125 (ic)\", \"gpt-4-0613 (ic)\"]\n",
    "markers = [\"X\" if m in slm else (\"o\" if m in in_context else \".\") for m in methods]\n",
    "\n",
    "\n",
    "# matplotlib.rcParams.update({'font.size': })\n",
    "plt.rc('text', usetex=False)\n",
    "sns.set_theme(style=\"whitegrid\", font_scale=1.0)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(6, 4))\n",
    "gs = fig.add_gridspec(nrows=2, ncols=3, hspace=0.5, wspace=0.1)\n",
    "\n",
    "labels = list()\n",
    "handles = list()\n",
    "\n",
    "for i, query in enumerate([\"Scan\", \"Join\", \"Union\", \"Selection\", \"Aggregation\"]):\n",
    "    ax = fig.add_subplot(gs[i // 3, i % 3])\n",
    "\n",
    "    sns.lineplot(metrics[metrics[\"query\"] == query], y=\"mean_f1\", x=\"split_size\", hue=\"method\", ax=ax, dashes=False,\n",
    "                 hue_order=hue_methods[::-1], palette=sns.color_palette(color_palette[::-1]), marker = \"X\")  # style_order=methods[::-1] markers=markers[::-1], style=\"method\",\n",
    "    ax.set_title(query)\n",
    "\n",
    "    handles_ax, labels_ax = ax.get_legend_handles_labels()\n",
    "    handles.extend(handles_ax)\n",
    "    labels.extend(labels_ax)\n",
    "    ax.get_legend().remove()\n",
    "\n",
    "    ax.set_xscale(\"log\")\n",
    "    ax.set_xticks([4, 64, 1024])\n",
    "    ax.set_xticklabels([\"4\", \"64\", \"1024\"])\n",
    "    ax.set_yticks([0.2, 0.4, 0.6, 0.8])\n",
    "    ax.set_xlabel(\"Number of Labeled Texts\" if i == 4 else \"\")\n",
    "    ax.set_ylabel(\"Mean F1\")\n",
    "    ax.set_ylim((None, 1.0))\n",
    "    if i < 2:\n",
    "        ax.set_xlabel(None)\n",
    "        ax.set_xticklabels([\"\", \"\", \"\"])\n",
    "    if i % 3:\n",
    "        ax.set_ylabel(None)\n",
    "        ax.set_yticklabels([\"\", \"\", \"\", \"\"])\n",
    "\n",
    "print(labels)\n",
    "hl_dict = {l.split(\"_\")[0]: h for l, h in zip(labels, handles)}\n",
    "print(hl_dict)\n",
    "leg = fig.legend([hl_dict[l] for l in methods], methods, bbox_to_anchor=(0.65, 0.07), ncol=1, loc='lower left', borderaxespad=0., frameon=False)\n",
    "\n",
    "plt.savefig(\"/home/murban/exp2.pdf\", bbox_inches=\"tight\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
